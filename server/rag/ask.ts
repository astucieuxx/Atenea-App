/**
 * ATENEA RAG - Endpoint /ask
 * 
 * Genera respuestas a preguntas jur√≠dicas usando RAG.
 * 
 * Flujo:
 * 1. Recibe pregunta en espa√±ol
 * 2. Recupera tesis relevantes (vectorial + full-text)
 * 3. Genera respuesta con LLM citando tesis
 * 4. Retorna respuesta + tesis usadas
 * 
 * Restricciones:
 * - NO inventar respuestas sin evidencia
 * - Citar obligatoriamente tesis usadas (ID + rubro)
 * - Indicar expl√≠citamente si no hay tesis aplicables
 */

import {
  retrieveRelevantDocuments,
  formatTesisCitation,
  formatPrecedenteCitation,
  formatTesisFormalCitation,
  formatPrecedenteFormalCitation,
  type RetrievedTesis,
  type RetrievedPrecedente,
} from "./retrieval";

// ============================================================================
// CONFIGURACI√ìN
// ============================================================================

export interface ConversationMessage {
  role: "user" | "assistant";
  content: string;
}

export interface AskConfig {
  maxTesis: number; // M√°ximo de tesis a usar en la respuesta
  minRelevance: number; // Relevancia m√≠nima para usar una tesis
  useLLM: boolean; // Si false, solo retorna tesis sin generar respuesta
  llmProvider?: "openai" | "anthropic"; // Proveedor de LLM
  llmModel?: string; // Modelo espec√≠fico
  conversationHistory?: ConversationMessage[]; // Historial de conversaci√≥n
}

export const DEFAULT_ASK_CONFIG: AskConfig = {
  maxTesis: 5,
  minRelevance: 0.3, // Reducido de 0.5 a 0.3 para ser m√°s permisivo
  useLLM: true,
  llmProvider: "openai",
  llmModel: "gpt-4o-mini",
};

// ============================================================================
// RESPUESTA DEL ENDPOINT
// ============================================================================

export interface AskResponse {
  answer: string;
  tesisUsed: Array<{
    id: string;
    title: string;
    citation: string;
    formalCitation: string;
    relevanceScore: number;
    source?: "tesis" | "precedente";
    url?: string;
  }>;
  hasEvidence: boolean;
  confidence: "high" | "medium" | "low";
  tokenUsage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

// ============================================================================
// DETECCI√ìN DE FOLLOW-UPS vs PREGUNTAS NUEVAS
// ============================================================================

/**
 * Determina si una pregunta necesita retrieval completo o es un follow-up
 * que puede responderse con el historial de conversaci√≥n existente.
 */
function needsRetrieval(question: string, conversationHistory?: ConversationMessage[]): boolean {
  // Must have a real conversation: at least one prior assistant response
  // This prevents treating the first message as follow-up even when localStorage loads old messages
  const hasRealConversation = conversationHistory
    && conversationHistory.length >= 2
    && conversationHistory.some(m => m.role === "assistant");

  if (!hasRealConversation) {
    console.log(`[üîç RETRIEVAL] No hay conversaci√≥n previa con respuesta de Atenea, ejecutando retrieval`);
    return true;
  }

  const q = question.toLowerCase().trim();
  const wordCount = q.split(/\s+/).length;

  // === SE√ëALES DE PREGUNTA NUEVA (S√ç necesita retrieval) - EVALUAR PRIMERO ===

  // 1. Menciona art√≠culos, leyes o c√≥digos espec√≠ficos
  const legalRefPattern = /\b(art√≠culo|art\.?)\s+\d+|c√≥digo\s+(fiscal|civil|penal|comercio)|ley\s+(federal|general|de|del)/i;
  const hasLegalRef = legalRefPattern.test(q);

  // 2. Pregunta larga y sustantiva (> 15 palabras)
  const isLongQuestion = wordCount > 15;

  // 3. Contiene t√©rminos jur√≠dicos espec√≠ficos (any length - even short queries)
  const legalTerms = [
    "prescripci√≥n", "caducidad", "amparo", "jurisprudencia", "sentencia",
    "recurso", "apelaci√≥n", "casaci√≥n", "nulidad", "inconstitucionalidad",
    "competencia", "jurisdicci√≥n", "litispendencia", "cosa juzgada",
    "defraudaci√≥n", "homicidio", "robo", "fraude", "responsabilidad",
    "indemnizaci√≥n", "reparaci√≥n", "da√±o", "perjuicio",
  ];
  const hasLegalTerms = legalTerms.some(term => q.includes(term));

  // Legal terms with 5+ words = new query (lowered from 8)
  const isNewLegalQuery = hasLegalTerms && wordCount >= 5;

  // If it has strong signals of being a new question ‚Üí always retrieval
  if (hasLegalRef || isLongQuestion || isNewLegalQuery) {
    console.log(`[üîç RETRIEVAL] Pregunta nueva detectada: "${question.substring(0, 60)}..." (legalRef=${hasLegalRef}, long=${isLongQuestion}, newLegal=${isNewLegalQuery})`);
    return true;
  }

  // === SE√ëALES DE FOLLOW-UP (NO necesita retrieval) - EVALUAR DESPU√âS ===

  // 1. Empieza con palabras de continuaci√≥n
  const followUpStarters = [
    "y ", "pero ", "entonces ", "explica", "detalla", "ampl√≠a", "profundiza",
    "qu√© m√°s", "tambi√©n ", "adem√°s ", "a qu√© te refieres",
    "c√≥mo as√≠", "en qu√© sentido", "dame ",
    "cu√©ntame m√°s", "sigue", "contin√∫a", "elabora",
  ];
  const startsWithFollowUp = followUpStarters.some(starter => q.startsWith(starter));

  // 2. Contiene referencias pronominales (strict: only standalone pronoun usage, not adjectives)
  const pronounPatterns = [
    /\bsobre (eso|esto)\b/,
    /\bde (eso|esto|lo anterior)\b/,
    /\b(lo|la|los|las) (anterior|mencionado|dicho|explicado)\b/,
    /\b(al respecto)\b/,
    /\b(el mismo|la misma|los mismos|las mismas) (tema|punto|criterio|asunto)\b/,
    /\b¬ø(y|qu√© hay de) (eso|esto)\?/,
  ];
  const hasPronouns = pronounPatterns.some(p => p.test(q));

  // 3. Very short questions with interrogation (< 6 words, more restrictive)
  const isShortQuestion = wordCount < 6 && (q.includes("?") || q.includes("¬ø"));

  // 4. Solicitudes de filtrado/formato sobre resultados previos
  const filterPatterns = [
    /^solo (precedentes|tesis|jurisprudencia)/,
    /^muestra(me)? (solo|los|las)/,
    /^filtra/,
    /^ordena/,
    /^resumen|^resume/,
    /^en resumen/,
    /^simplifica/,
  ];
  const isFilterRequest = filterPatterns.some(p => p.test(q));

  // If it has follow-up signals ‚Üí skip retrieval
  if (startsWithFollowUp || hasPronouns || isShortQuestion || isFilterRequest) {
    console.log(`[üí¨ FOLLOW-UP] Follow-up detectado: "${question.substring(0, 60)}..." (starter=${startsWithFollowUp}, pronouns=${hasPronouns}, short=${isShortQuestion}, filter=${isFilterRequest})`);
    return false;
  }

  // Por defecto, hacer retrieval (es m√°s seguro)
  console.log(`[üîç RETRIEVAL] Default: ejecutando retrieval para "${question.substring(0, 60)}..."`);
  return true;
}

// ============================================================================
// GENERACI√ìN DE RESPUESTA CON LLM
// ============================================================================

async function generateAnswerWithLLM(
  question: string,
  retrievedTesis: RetrievedTesis[],
  retrievedPrecedentes: RetrievedPrecedente[] = [],
  conversationHistory?: ConversationMessage[],
  hasRetrievalContext: boolean = true,
): Promise<{ answer: string; tokenUsage: { promptTokens: number; completionTokens: number; totalTokens: number } }> {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    console.error("[generateAnswerWithLLM] ERROR: OPENAI_API_KEY no est√° configurada");
    throw new Error("OPENAI_API_KEY environment variable is required");
  }
  
  // Verificar que la API key tenga el formato correcto
  if (!apiKey.startsWith('sk-')) {
    console.warn("[generateAnswerWithLLM] WARNING: La API key no parece tener el formato correcto (deber√≠a empezar con 'sk-')");
  }
  
  console.log("[generateAnswerWithLLM] API Key configurada (primeros 10 caracteres):", apiKey.substring(0, 10) + "...");

  // Construir contexto con tesis recuperadas (incluye todos los datos para referencias)
  const tesisContext = retrievedTesis
    .map((rt, idx) => {
      const citation = formatTesisCitation(rt.tesis);
      return `TESIS ${idx + 1} (ID: ${rt.tesis.id}):
Rubro: "${rt.tesis.title}"
N√∫mero de tesis: ${rt.tesis.tesis_numero || "N/A"}
Registro digital: ${rt.tesis.id}
√âpoca: ${rt.tesis.epoca || "N/A"}
Materia: ${rt.tesis.materias || "N/A"}
Instancia: ${rt.tesis.instancia || rt.tesis.organo_jurisdiccional || "N/A"}
Tipo: ${rt.tesis.tipo || "N/A"}
Cita: ${citation}
Contenido relevante: ${rt.chunkText.slice(0, 300)}...`;
    })
    .join("\n\n");

  // Construir contexto con precedentes recuperados
  const precedentesContext = retrievedPrecedentes
    .map((rp, idx) => {
      const citation = formatPrecedenteCitation(rp.precedente);
      return `PRECEDENTE ${idx + 1} (ID: ${rp.precedente.id}, IUS: ${rp.precedente.ius}):
Rubro: "${rp.precedente.rubro}"
Cita: ${citation}
Contenido relevante: ${rp.chunkText.slice(0, 300)}...`;
    })
    .join("\n\n");

  // Prompt estructurado para respuesta jur√≠dica profesional con formato visual
  const systemPrompt = `# Atenea - Asistente de Jurisprudencia Mexicana

Eres Atenea, asistente especializada en jurisprudencia mexicana. Tu objetivo es proporcionar an√°lisis jur√≠dicos precisos, √∫tiles y fundamentados exclusivamente en las tesis del contexto.

## Principio Fundamental: Utilidad sobre Restricciones

**Siempre formula una respuesta √∫til.** Nunca digas "no encontr√©", "no hay informaci√≥n", o "no puedo responder". Trabaja con la informaci√≥n disponible y s√© claro sobre su alcance.

## Reglas de Contenido

### 1. Fuente √önica de Verdad
- Responde **exclusivamente** con las tesis proporcionadas en el contexto
- **NUNCA** inventes normas, precedentes, art√≠culos o criterios
- Si no hay tesis exactas, usa informaci√≥n relacionada y explica su aplicabilidad
- No menciones "las tesis disponibles" o "el contexto RAG" - el usuario no necesita saber c√≥mo funciona el sistema

### 2. Sistema de Referencias
- Usa referencias numeradas inline: [1], [2], [3]
- TESIS 1 del contexto = [1], TESIS 2 = [2], etc.
- Prioriza jurisprudencia vigente sobre tesis aisladas

### 3. Manejo de Diferentes Tipos de Preguntas

**Preguntas jur√≠dicas con tesis disponibles:**
‚Üí Responde directamente con fundamentaci√≥n

**Preguntas jur√≠dicas sin tesis exactas:**
‚Üí Usa informaci√≥n relacionada y s√© claro sobre su alcance y aplicabilidad

**Preguntas no jur√≠dicas:**
‚Üí Responde naturalmente, luego redirige amablemente a temas jur√≠dicos

**Solicitudes de recomendaciones:**
‚Üí Sugiere temas √∫tiles basados en las tesis disponibles

## Tono y Estilo

### Prohibiciones Absolutas
‚ùå NO inicies con muletillas: "Claro", "Pues", "Bien", "Entonces", "Por supuesto", "Sin duda"
‚ùå NO uses frases de relleno o introducciones gen√©ricas
‚ùå NO expliques procedimientos cuando preguntan resultados
‚ùå NO digas "no encontr√©", "no hay", "no se puede determinar", "no entiendo tu pregunta"

### Obligaciones
‚úÖ Lenguaje profesional: directo, preciso, objetivo
‚úÖ Usa **negritas** para conceptos jur√≠dicos clave
‚úÖ Empieza directamente con la respuesta o contexto pertinente
‚úÖ Termina con pregunta de seguimiento conversacional

## Estructura de Respuesta

### Para Preguntas Binarias (S√≠/No)
1. Respuesta directa: "S√≠/No/Depende, [breve fundamentaci√≥n]"
2. Contexto jur√≠dico con puntos estructurados
3. Criterios aplicables [1], [2], [3] con **conceptos clave** en negritas
4. Pregunta de seguimiento

### Para An√°lisis o Explicaci√≥n
1. Contexto jur√≠dico (2-3 l√≠neas)
2. Criterios numerados:
   - 1. **Primer criterio** - Explicaci√≥n [1]
   - 2. **Segundo criterio** - Explicaci√≥n [2]
3. S√≠ntesis clave
4. Pregunta de seguimiento

## Formato

- Usa n√∫meros (1., 2., 3.) para puntos principales
- Usa guiones (-) para subpuntos
- NO uses emojis ni s√≠mbolos decorativos
- NO incluyas secciones "REFERENCIAS:" o "SUGERENCIAS:" (se generan autom√°ticamente)

## Ejemplos

**Ejemplo 1 - Pregunta Binaria:**
Pregunta: "¬øAlguna empresa ha ganado contra la CNSF?"

Respuesta:
"La jurisprudencia establece que las empresas pueden impugnar resoluciones de la CNSF mediante:

1. **Juicio de nulidad** - Procede cuando existe **inter√©s jur√≠dico** por afectaci√≥n a la posici√≥n competitiva [1]
2. **Juicio de amparo** - Las resoluciones de la CNSF son impugnables por esta v√≠a [3]

La procedencia depende de demostrar **afectaci√≥n directa** a derechos o posici√≥n competitiva.

¬øTe interesa conocer los requisitos espec√≠ficos para alguna de estas v√≠as?"

**Ejemplo 2 - Recomendaciones:**
Pregunta: "¬øQu√© me recomiendas buscar?"

Respuesta:
"Te recomiendo explorar estos criterios fundamentales:

1. **Quejas en cumplimiento de sentencias de amparo** - Procedimientos y requisitos [1]
2. **Contradicciones en jurisprudencia** - Mecanismos de resoluci√≥n por la SCJN [2]
3. **Requisitos probatorios en amparo** - Est√°ndares para pruebas testimoniales y periciales [3]

¬øHay alg√∫n √°rea espec√≠fica del derecho que te interese m√°s?"

**Ejemplo 3 - Pregunta No Jur√≠dica:**
Pregunta: "¬øCu√°ndo se fund√≥ M√©xico?"

Respuesta:
"M√©xico consum√≥ su independencia el 27 de septiembre de 1821.

Estoy especializada en jurisprudencia y criterios legales mexicanos. Si tienes preguntas sobre derecho constitucional, historia jur√≠dica de M√©xico, o cualquier tema de jurisprudencia, estar√© encantada de ayudarte."

---

**Recuerda:** Tu objetivo es ser √∫til, precisa y conversacional. Ayuda al usuario a navegar la jurisprudencia mexicana de manera clara y pr√°ctica.`;

  // Build user prompt conditionally based on whether we have retrieval context
  let userPrompt: string;

  if (hasRetrievalContext) {
    userPrompt = `Pregunta: ${question}

Tesis relevantes:
${tesisContext}
${precedentesContext ? `\nPrecedentes judiciales relevantes:\n${precedentesContext}` : ""}

---

INSTRUCCIONES:

1. **Identifica el tipo de pregunta:**
   - ¬øBinaria (s√≠/no)? ‚Üí Responde S√ç/NO/DEPENDE + fundamentaci√≥n
   - ¬øSolicita casos/ejemplos? ‚Üí Presenta informaci√≥n relacionada disponible
   - ¬øPide an√°lisis? ‚Üí Contexto + criterios estructurados
   - ¬øNo jur√≠dica? ‚Üí Responde naturalmente + redirige a temas jur√≠dicos
   - ¬øRecomendaciones? ‚Üí Sugiere temas √∫tiles basados en las tesis

2. **Usa SOLO la informaci√≥n proporcionada:**
   - Las tesis y precedentes arriba son tu √∫nica fuente
   - Si no hay tesis exactas, usa informaci√≥n relacionada siendo claro sobre su alcance
   - NUNCA inventes tesis, art√≠culos o criterios
   - NUNCA digas "no encontr√©" o "no hay informaci√≥n"

3. **Estructura tu respuesta:**

   **Si es pregunta binaria:**
   - L√≠nea 1: Respuesta directa (S√≠/No/Depende + breve raz√≥n)
   - Desarrollo: Puntos estructurados con contexto jur√≠dico
   - Referencias: [1], [2], [3] en texto con **negritas** en conceptos clave
   - Final: Pregunta de seguimiento

   **Si es an√°lisis:**
   - Inicio: Contexto jur√≠dico (2-3 l√≠neas)
   - Desarrollo: Criterios numerados (1., 2., 3.)
   - Referencias: [1], [2], [3] inline
   - S√≠ntesis: Punto clave
   - Final: Pregunta de seguimiento

4. **Tono profesional y directo:**
   - NO inicies con: "Claro", "Pues", "Bien", "Entonces", "Por supuesto"
   - S√ç empieza directo con la respuesta
   - USA **negritas** para conceptos jur√≠dicos clave
   - TERMINA con pregunta conversacional

5. **Referencias:**
   - [1] = Primera tesis del contexto
   - [2] = Segunda tesis del contexto
   - [3] = Tercera tesis del contexto
   - NO incluyas secci√≥n "REFERENCIAS:" (se genera autom√°ticamente)

6. **Formato:**
   - N√∫meros (1., 2., 3.) para puntos principales
   - Guiones (-) para subpuntos
   - Sin emojis ni s√≠mbolos decorativos`;
  } else {
    // Follow-up: no retrieval context, rely on conversation history
    userPrompt = `Pregunta: ${question}

Esta es una pregunta de seguimiento basada en la conversaci√≥n anterior.

INSTRUCCIONES:
1. Responde bas√°ndote en la informaci√≥n ya proporcionada en mensajes anteriores de la conversaci√≥n.
2. Usa las tesis y precedentes que ya fueron citados previamente como referencia.
3. Mant√©n las mismas referencias [1], [2], [3] de la respuesta anterior si aplica.
4. Si la pregunta requiere informaci√≥n completamente nueva que no fue discutida, ind√≠calo al usuario.
5. Mant√©n tono profesional y directo, sin muletillas.
6. USA **negritas** para conceptos jur√≠dicos clave.
7. TERMINA con pregunta de seguimiento conversacional.
8. Sin emojis ni s√≠mbolos decorativos.`;
  }

  try {
    // Limpiar la API key (eliminar espacios al inicio/final)
    const cleanApiKey = apiKey.trim();
    if (cleanApiKey !== apiKey) {
      console.warn("[generateAnswerWithLLM] La API key ten√≠a espacios, se limpiaron autom√°ticamente");
    }
    
    console.log("[generateAnswerWithLLM] Enviando petici√≥n a OpenAI API...");
    console.log("[generateAnswerWithLLM] URL: https://api.openai.com/v1/chat/completions");
    console.log("[generateAnswerWithLLM] Model: gpt-4o-mini");
    
    // Crear un AbortController para timeout
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 60000); // 60 segundos timeout
    
    try {
      const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${cleanApiKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "gpt-4o-mini",
          messages: [
            { role: "system", content: systemPrompt },
            // Include conversation history (excluding the current message) for context
            ...(conversationHistory && conversationHistory.length > 1
              ? conversationHistory.slice(0, -1).map(msg => ({
                  role: msg.role as "user" | "assistant",
                  content: msg.content,
                }))
              : []),
            { role: "user", content: userPrompt },
          ],
          temperature: 0.1,
          max_tokens: 1200,
        }),
        signal: controller.signal,
      });
      
      clearTimeout(timeoutId);

      console.log("[generateAnswerWithLLM] Respuesta recibida, status:", response.status, response.statusText);

      if (!response.ok) {
        const errorText = await response.text();
        let errorData;
        try {
          errorData = JSON.parse(errorText);
        } catch {
          errorData = { error: errorText };
        }
        
        console.error("[generateAnswerWithLLM] ERROR de API:");
        console.error("  Status:", response.status, response.statusText);
        console.error("  Error completo:", JSON.stringify(errorData, null, 2));
        console.error("  Headers de respuesta:", Object.fromEntries(response.headers.entries()));
        
        // Errores espec√≠ficos de autenticaci√≥n
        if (response.status === 401 || response.status === 403) {
          const errorMsg = errorData.error?.message || errorData.error?.code || errorData.error || 'API key inv√°lida o expirada';
          console.error("[generateAnswerWithLLM] ERROR DE AUTENTICACI√ìN:");
          console.error("  - Verifica que la API key sea v√°lida y no est√© expirada");
          console.error("  - Verifica que tengas cr√©ditos disponibles en tu cuenta de OpenAI");
          console.error("  - Verifica que la API key tenga los permisos necesarios");
          throw new Error(`Error de autenticaci√≥n con OpenAI: ${errorMsg}`);
        }
        
        // Error de conexi√≥n
        if (response.status === 0 || errorText.includes("connection") || errorText.includes("network")) {
          console.error("[generateAnswerWithLLM] ERROR DE CONEXI√ìN:");
          console.error("  - Verifica tu conexi√≥n a internet");
          console.error("  - Verifica que puedas acceder a api.openai.com");
          throw new Error(`Error de conexi√≥n con OpenAI: ${errorData.error?.message || errorData.error || 'No se pudo conectar con la API'}`);
        }
        
        throw new Error(`OpenAI API error (${response.status}): ${errorData.error?.message || JSON.stringify(errorData)}`);
      }

      const data = await response.json();
      let answer = data.choices[0]?.message?.content || "No se pudo generar una respuesta.";
    
    // Post-procesamiento: eliminar frases casuales al inicio
    const casualPhrases = [
      /^Claro,\s*/i,
      /^Bien,\s*/i,
      /^Entonces,\s*/i,
      /^Pues,\s*/i,
      /^As√≠ que,\s*/i,
      /^Por supuesto,\s*/i,
      /^Desde luego,\s*/i,
      /^Evidentemente,\s*/i,
      /^Naturalmente,\s*/i,
      /^Ciertamente,\s*/i,
      /^Sin duda,\s*/i,
      /^Por cierto,\s*/i,
      /^Bueno,\s*/i,
      /^Mira,\s*/i,
      /^Oye,\s*/i,
    ];
    
    for (const phrase of casualPhrases) {
      answer = answer.replace(phrase, '');
    }
    
    // Limpiar espacios m√∫ltiples al inicio
    answer = answer.trim();
    
    // Log completo de la respuesta para debug
    console.log("[generateAnswerWithLLM] Full API response keys:", Object.keys(data));
    console.log("[generateAnswerWithLLM] Usage field exists:", !!data.usage);
    console.log("[generateAnswerWithLLM] Usage field value:", JSON.stringify(data.usage, null, 2));
    
    // Extraer informaci√≥n de tokens de la respuesta
    // La API de OpenAI siempre deber√≠a incluir 'usage', pero verificamos por si acaso
    let tokenUsage;
    if (data.usage) {
      tokenUsage = {
        promptTokens: data.usage.prompt_tokens || 0,
        completionTokens: data.usage.completion_tokens || 0,
        totalTokens: data.usage.total_tokens || 0,
      };
    } else {
      // Si no hay usage, intentar calcular aproximado o usar valores por defecto
      console.warn("[generateAnswerWithLLM] WARNING: API response does not include 'usage' field");
      tokenUsage = {
        promptTokens: 0,
        completionTokens: 0,
        totalTokens: 0,
      };
    }
    
    // Log para debug
    console.log("[generateAnswerWithLLM] Extracted token usage:", tokenUsage);
    
      return { answer, tokenUsage };
    } catch (fetchError: any) {
      clearTimeout(timeoutId);
      
      // Manejar errores de abort (timeout)
      if (fetchError.name === 'AbortError') {
        console.error("[generateAnswerWithLLM] ERROR: Timeout al conectar con OpenAI (60 segundos)");
        throw new Error("Timeout al conectar con OpenAI. Verifica tu conexi√≥n a internet.");
      }
      
      // Manejar errores de conexi√≥n
      if (fetchError.message?.includes("fetch failed") || 
          fetchError.message?.includes("ECONNREFUSED") ||
          fetchError.message?.includes("ENOTFOUND") ||
          fetchError.message?.includes("connection")) {
        console.error("[generateAnswerWithLLM] ERROR DE CONEXI√ìN:");
        console.error("  Mensaje:", fetchError.message);
        console.error("  Stack:", fetchError.stack);
        console.error("  Posibles causas:");
        console.error("    - Problema de conexi√≥n a internet");
        console.error("    - Firewall bloqueando api.openai.com");
        console.error("    - Proxy o VPN interfiriendo");
        throw new Error(`Error de conexi√≥n con OpenAI: ${fetchError.message || 'No se pudo establecer conexi√≥n'}`);
      }
      
      // Re-lanzar otros errores
      throw fetchError;
    }
  } catch (error) {
    console.error("[generateAnswerWithLLM] ERROR capturado:", error);
    if (error instanceof Error) {
      console.error("[generateAnswerWithLLM] Error message:", error.message);
      console.error("[generateAnswerWithLLM] Error stack:", error.stack);
      
      // Si es un error de autenticaci√≥n, dar m√°s informaci√≥n
      if (error.message.includes("autenticaci√≥n") || error.message.includes("401") || error.message.includes("403")) {
        console.error("[generateAnswerWithLLM] PROBLEMA DE AUTENTICACI√ìN DETECTADO:");
        console.error("  - Verifica que OPENAI_API_KEY est√© configurada correctamente en el archivo .env");
        console.error("  - Verifica que la API key sea v√°lida y no est√© expirada");
        console.error("  - Verifica que tengas cr√©ditos disponibles en tu cuenta de OpenAI");
      }
    }
    throw error;
  }
}

// ============================================================================
// FUNCI√ìN PRINCIPAL: /ask
// ============================================================================

export async function askQuestion(
  question: string,
  config: Partial<AskConfig> & { conversationHistory?: ConversationMessage[] } = {}
): Promise<AskResponse> {
  // Merge with defaults
  const fullConfig: AskConfig = { ...DEFAULT_ASK_CONFIG, ...config };
  const { conversationHistory } = config;

  if (!question || question.trim().length < 10) {
    throw new Error("La pregunta debe tener al menos 10 caracteres");
  }

  // PASO 0: Detectar si es follow-up o pregunta nueva
  const shouldRetrieve = needsRetrieval(question, conversationHistory);

  if (!shouldRetrieve) {
    // CAMINO A: Follow-up sin retrieval - respuesta r√°pida usando historial
    try {
      const llmResult = await generateAnswerWithLLM(
        question,
        [], // No tesis
        [], // No precedentes
        conversationHistory,
        false, // hasRetrievalContext = false
      );
      console.log(`[üí¨ FOLLOW-UP] Respuesta generada sin retrieval`);
      return {
        answer: llmResult.answer,
        tesisUsed: [], // No hay nuevas tesis (el frontend muestra las de la respuesta anterior)
        hasEvidence: true, // Basado en historial
        confidence: "medium",
        tokenUsage: llmResult.tokenUsage,
      };
    } catch (error) {
      console.error("[FOLLOW-UP] Error en follow-up, fallback a retrieval completo:", error);
      // Si falla, caer al camino B (retrieval completo)
    }
  }

  // CAMINO B: Pregunta nueva con retrieval completo
  // Paso 1: Recuperar tesis y precedentes relevantes
  const { tesis: retrievedTesis, precedentes: retrievedPrecedentes } = await retrieveRelevantDocuments(question, {
    maxResults: fullConfig.maxTesis * 2,
    finalLimit: fullConfig.maxTesis,
    minSimilarity: fullConfig.minRelevance,
    vectorWeight: 0.7,
    textWeight: 0.3,
    deduplicateByTesis: true,
    includePrecedentes: true,
  });

  // Paso 2: Verificar si hay evidencia suficiente
  const hasEvidence = retrievedTesis.length > 0 || retrievedPrecedentes.length > 0;

  if (!hasEvidence) {
    return {
      answer: "No se encontr√≥ jurisprudencia ni precedentes directamente aplicables a esta pregunta. Se recomienda reformular la consulta con t√©rminos jur√≠dicos m√°s espec√≠ficos o consultar otras fuentes.",
      tesisUsed: [],
      hasEvidence: false,
      confidence: "low",
    };
  }

  // Filtrar tesis con relevancia muy baja (menor a 0.2) antes de enviar al LLM
  const filteredTesis = retrievedTesis.filter(rt => rt.relevanceScore >= 0.2);
  const tesisToUse = filteredTesis.length > 0 ? filteredTesis : retrievedTesis;

  // Filtrar precedentes igual
  const filteredPrecedentes = retrievedPrecedentes.filter(rp => rp.relevanceScore >= 0.2);
  const precedentesToUse = filteredPrecedentes.length > 0 ? filteredPrecedentes : retrievedPrecedentes;

  // Paso 3: Generar respuesta (con LLM o sin √©l)
  let answer: string;
  let tokenUsage: { promptTokens: number; completionTokens: number; totalTokens: number } | undefined;
  
  if (fullConfig.useLLM) {
    try {
      const llmResult = await generateAnswerWithLLM(question, tesisToUse, precedentesToUse, conversationHistory, true);
      answer = llmResult.answer;
      tokenUsage = llmResult.tokenUsage;
      console.log("[askQuestion] Token usage received:", tokenUsage);
    } catch (error) {
      console.error("[askQuestion] Error generating answer with LLM, falling back to simple format");
      console.error("[askQuestion] Error details:", error instanceof Error ? error.message : String(error));
      // Fallback: respuesta simple sin LLM
      answer = generateSimpleAnswer(question, tesisToUse);
      // Agregar nota sobre el error al inicio de la respuesta
      answer = `‚ö†Ô∏è No se pudo generar una respuesta con IA debido a un error de conexi√≥n. Mostrando tesis encontradas:\n\n${answer}`;
      tokenUsage = {
        promptTokens: 0,
        completionTokens: 0,
        totalTokens: 0,
      };
    }
  } else {
    answer = generateSimpleAnswer(question, tesisToUse);
    tokenUsage = {
      promptTokens: 0,
      completionTokens: 0,
      totalTokens: 0,
    };
  }

  // Paso 4: Determinar confianza basada en tesis + precedentes
  const allScores = [
    ...tesisToUse.map(rt => rt.relevanceScore),
    ...precedentesToUse.map(rp => rp.relevanceScore),
  ];
  const totalDocs = allScores.length;
  const avgRelevance = totalDocs > 0 ? allScores.reduce((sum, s) => sum + s, 0) / totalDocs : 0;
  let confidence: "high" | "medium" | "low";
  let finalHasEvidence = true;

  if (avgRelevance >= 0.6 && totalDocs >= 3) {
    confidence = "high";
  } else if (avgRelevance >= 0.4 && totalDocs >= 2) {
    confidence = "medium";
  } else if (avgRelevance >= 0.3 && totalDocs >= 1) {
    confidence = "low";
  } else {
    confidence = "low";
    finalHasEvidence = false;
  }

  // Paso 5: Formatear tesis y precedentes usados
  const tesisUsed = [
    ...tesisToUse.map(rt => ({
      id: rt.tesis.id,
      title: rt.tesis.title,
      citation: formatTesisCitation(rt.tesis),
      formalCitation: formatTesisFormalCitation(rt.tesis),
      relevanceScore: rt.relevanceScore,
      source: "tesis" as const,
      url: rt.tesis.url || undefined,
    })),
    ...precedentesToUse.map(rp => ({
      id: rp.precedente.id,
      title: rp.precedente.rubro,
      citation: formatPrecedenteCitation(rp.precedente),
      formalCitation: formatPrecedenteFormalCitation(rp.precedente),
      relevanceScore: rp.relevanceScore,
      source: "precedente" as const,
      url: rp.precedente.url_origen || undefined,
    })),
  ];

  // Asegurar que tokenUsage siempre est√© presente (incluso si es undefined, lo convertimos a un objeto con 0s)
  const finalTokenUsage = tokenUsage || {
    promptTokens: 0,
    completionTokens: 0,
    totalTokens: 0,
  };
  
  const response = {
    answer,
    tesisUsed,
    hasEvidence: finalHasEvidence,
    confidence,
    tokenUsage: finalTokenUsage,
  };
  
  console.log("[askQuestion] Final response with tokenUsage:", JSON.stringify(response, null, 2));
  console.log("[askQuestion] TokenUsage type:", typeof tokenUsage, "value:", tokenUsage);
  
  return response;
}

// ============================================================================
// RESPUESTA SIMPLE (sin LLM)
// ============================================================================

function generateSimpleAnswer(
  question: string,
  retrievedTesis: RetrievedTesis[]
): string {
  if (retrievedTesis.length === 0) {
    return "No se encontr√≥ jurisprudencia directamente aplicable a esta pregunta.";
  }

  let answer = `Se encontraron ${retrievedTesis.length} tesis relevantes para esta consulta:\n\n`;

  retrievedTesis.forEach((rt, idx) => {
    answer += `${idx + 1}. [ID: ${rt.tesis.id}] "${rt.tesis.title}"\n`;
    answer += `   ${formatTesisCitation(rt.tesis)}\n`;
    answer += `   Relevancia: ${(rt.relevanceScore * 100).toFixed(1)}%\n\n`;
  });

  answer += "Se recomienda revisar el contenido completo de estas tesis para una respuesta precisa.";

  return answer;
}
